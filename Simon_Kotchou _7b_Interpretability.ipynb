{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "csci470-nbs",
      "language": "python",
      "name": "csci470-nbs"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "<Simon Kotchou>-7b_Interpretability.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hez_ln5H8woJ"
      },
      "source": [
        "## CSCI 470 Activities and Case Studies\n",
        "\n",
        "1. For all activities, you are allowed to collaborate with a partner. \n",
        "1. For case studies, you should work individually and are **not** allowed to collaborate.\n",
        "\n",
        "By filling out this notebook and submitting it, you acknowledge that you are aware of the above policies and are agreeing to comply with them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITiEjrzu8woM"
      },
      "source": [
        "Some considerations with regard to how these notebooks will be graded:\n",
        "\n",
        "1. You can add more notebook cells or edit existing notebook cells other than \"# YOUR CODE HERE\" to test out or debug your code. We actually highly recommend you do so to gain a better understanding of what is happening. However, during grading, **these changes are ignored**. \n",
        "2. You must ensure that all your code for the particular task is available in the cells that say \"# YOUR CODE HERE\"\n",
        "3. Every cell that says \"# YOUR CODE HERE\" is followed by a \"raise NotImplementedError\". You need to remove that line. During grading, if an error occurs then you will not receive points for your work in that section.\n",
        "4. If your code passes the \"assert\" statements, then no output will result. If your code fails the \"assert\" statements, you will get an \"AssertionError\". Getting an assertion error means you will not receive points for that particular task.\n",
        "5. If you edit the \"assert\" statements to make your code pass, they will still fail when they are graded since the \"assert\" statements will revert to the original. Make sure you don't edit the assert statements.\n",
        "6. We may sometimes have \"hidden\" tests for grading. This means that passing the visible \"assert\" statements is not sufficient. The \"assert\" statements are there as a guide but you need to make sure you understand what you're required to do and ensure that you are doing it correctly. Passing the visible tests is necessary but not sufficient to get the grade for that cell.\n",
        "7. When you are asked to define a function, make sure you **don't** use any variables outside of the parameters passed to the function. You can think of the parameters being passed to the function as a hint. Make sure you're using all of those variables.\n",
        "8. Finally, **make sure you run \"Kernel > Restart and Run All\"** and pass all the asserts before submitting. If you don't restart the kernel, there may be some code that you ran and deleted that is still being used and that was why your asserts were passing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GVqpAkH8woN"
      },
      "source": [
        "# Model Interpretability\n",
        "\n",
        "In this exercise you'll use the [alibi](https://docs.seldon.io/projects/alibi/en/stable/) library to explain why some models make the predictions they do."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxAouJwE8woO",
        "outputId": "addbfbcb-eb03-4103-8625-dd97fd42afe4"
      },
      "source": [
        "! pip install alibi"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting alibi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/c1/7e6bbb4a69d84063d84dbf39ef5f95d9ee230379c542bed4e44ca8b878d8/alibi-0.5.5-py3-none-any.whl (228kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 19.7MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20kB 15.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 30kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 40kB 12.1MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 51kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 61kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 71kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 81kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 92kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 102kB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 112kB 10.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 122kB 10.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 133kB 10.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 143kB 10.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 153kB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 163kB 10.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 174kB 10.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 184kB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 194kB 10.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 204kB 10.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 215kB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 225kB 10.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235kB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from alibi) (20.3.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from alibi) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from alibi) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from alibi) (2.23.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from alibi) (0.22.2.post1)\n",
            "Requirement already satisfied: spacy[lookups] in /usr/local/lib/python3.6/dist-packages (from alibi) (2.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from alibi) (4.6.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from alibi) (1.1.5)\n",
            "Collecting shap>=0.36\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/a3/c0eab9dd6a894165e2cb87504ff5b2710ac5ede3447d9138620b7341b6a2/shap-0.37.0.tar.gz (326kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image!=0.17.1 in /usr/local/lib/python3.6/dist-packages (from alibi) (0.16.2)\n",
            "Requirement already satisfied: tensorflow>=2.0 in /usr/local/lib/python3.6/dist-packages (from alibi) (2.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from alibi) (3.2.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.2 in /usr/local/lib/python3.6/dist-packages (from alibi) (3.7.4.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from alibi) (1.4.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->alibi) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->alibi) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->alibi) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->alibi) (2020.12.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->alibi) (0.17.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (3.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (2.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (50.3.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (4.41.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (0.8.0)\n",
            "Collecting spacy-lookups-data<0.2.0,>=0.0.5; extra == \"lookups\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/4a37ca7d0c21dc2287a8bb5d249f5f3211cdf3d598acf742bf5bb8c87169/spacy_lookups_data-0.1.0.tar.gz (28.0MB)\n",
            "\u001b[K     |████████████████████████████████| 28.0MB 159kB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->alibi) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->alibi) (2.8.1)\n",
            "Collecting slicer==0.0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/02/a6/c708c5a0f338e99cfbcb6288b88794525548e4fc1b8457feec2c552a81a4/slicer-0.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from shap>=0.36->alibi) (0.48.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image!=0.17.1->alibi) (2.5)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image!=0.17.1->alibi) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image!=0.17.1->alibi) (2.4.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (2.10.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (0.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (1.34.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (0.36.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (2.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (2.3.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (0.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->alibi) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->alibi) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->alibi) (2.4.7)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy[lookups]->alibi) (3.1.1)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->shap>=0.36->alibi) (0.31.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image!=0.17.1->alibi) (4.4.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.0->alibi) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.0->alibi) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.0->alibi) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.0->alibi) (0.4.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.0->alibi) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy[lookups]->alibi) (3.4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.0->alibi) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.0->alibi) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.0->alibi) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.0->alibi) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.0->alibi) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.0->alibi) (3.1.0)\n",
            "Building wheels for collected packages: shap, spacy-lookups-data\n",
            "  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shap: filename=shap-0.37.0-cp36-cp36m-linux_x86_64.whl size=463891 sha256=95bd871b0228221fc1a924bd80fac2ae21c18f7d6a0e649fa645a3b600347699\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/ad/b0/aa7815ec68850d66551ef618095eccb962c8f6022f1d3dd989\n",
            "  Building wheel for spacy-lookups-data (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spacy-lookups-data: filename=spacy_lookups_data-0.1.0-py2.py3-none-any.whl size=28052144 sha256=6b1b9dc1134b9362a83a2a7f5651c2e23c0cef7d071bdefbbde8c33edaf2427f\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/2b/0a/d6fb6235c56d014d224bca760d15d7cbdd820813085ffcd35d\n",
            "Successfully built shap spacy-lookups-data\n",
            "Installing collected packages: slicer, shap, alibi, spacy-lookups-data\n",
            "Successfully installed alibi-0.5.5 shap-0.37.0 slicer-0.0.3 spacy-lookups-data-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSw7q8I58woP"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwP5lISS8woQ"
      },
      "source": [
        "data = load_iris()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khlRiI5U8woR",
        "outputId": "5cd23c5c-0024-4602-dbf5-382dd8c628cb"
      },
      "source": [
        "print(data[\"DESCR\"])\n",
        "features = data[\"data\"]\n",
        "targets = data[\"target\"]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _iris_dataset:\n",
            "\n",
            "Iris plants dataset\n",
            "--------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 150 (50 in each of three classes)\n",
            "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            "        - sepal length in cm\n",
            "        - sepal width in cm\n",
            "        - petal length in cm\n",
            "        - petal width in cm\n",
            "        - class:\n",
            "                - Iris-Setosa\n",
            "                - Iris-Versicolour\n",
            "                - Iris-Virginica\n",
            "                \n",
            "    :Summary Statistics:\n",
            "\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "                    Min  Max   Mean    SD   Class Correlation\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
            "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
            "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
            "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: 33.3% for each of 3 classes.\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
            "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
            "Machine Learning Repository, which has two wrong data points.\n",
            "\n",
            "This is perhaps the best known database to be found in the\n",
            "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
            "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
            "data set contains 3 classes of 50 instances each, where each class refers to a\n",
            "type of iris plant.  One class is linearly separable from the other 2; the\n",
            "latter are NOT linearly separable from each other.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
            "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
            "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
            "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
            "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
            "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
            "     Structure and Classification Rule for Recognition in Partially Exposed\n",
            "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
            "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
            "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
            "     on Information Theory, May 1972, 431-433.\n",
            "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
            "     conceptual clustering system finds 3 classes in the data.\n",
            "   - Many, many more ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn-UEIZU8woR"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features, targets, random_state=0)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3RO77Ii8woT",
        "outputId": "2c4b45f5-ca32-442c-f859-95175221a0b8"
      },
      "source": [
        "print(len(X_test))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b45cd198f4a64554f3690cdf9c7792c6",
          "grade": false,
          "grade_id": "cell-1a782646da471586",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAV5kSim8woT",
        "outputId": "ab3b46c3-d17d-44b0-8373-3dc1ae93dee9"
      },
      "source": [
        "## Create 2 classifiers: rf_clf that is a Random Forest model, and svm_clf that is a Linear SVM model\n",
        "## Train them both on the training data\n",
        "## Use them to predict the test data - saving it to y_rf_pred and y_svm_pred respectively\n",
        "## You may consider using GridSearchCV to determine a hyperparameter search for both models.\n",
        "rf_param = { \n",
        "    'n_estimators': [200, 700],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "rf_clf = RandomForestClassifier(n_jobs=-1,max_features= 'auto' ,n_estimators=200, oob_score = True)\n",
        "rf_clf.fit(X_train,y_train)\n",
        "\n",
        "svm_clf = LinearSVC()\n",
        "svm_clf.fit(X_train,y_train)\n",
        "\n",
        "y_rf_pred = rf_clf.predict(X_test)\n",
        "y_svm_pred = svm_clf.predict(X_test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2327a90e98fdc548e354e54640fd9c5c",
          "grade": true,
          "grade_id": "cell-0591079d074b5029",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "4fQGLDfA8woU"
      },
      "source": [
        "assert len(y_rf_pred) == 38\n",
        "assert isinstance(rf_clf, RandomForestClassifier) or isinstance(rf_clf, GridSearchCV)\n",
        "assert len(y_svm_pred) == 38\n",
        "assert isinstance(svm_clf, LinearSVC) or isinstance(svm_clf, GridSearchCV)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsdEBJWv8woV",
        "outputId": "20ae6233-e325-4e71-b43c-bf7b05ef71c9"
      },
      "source": [
        "print(f\"The random forest model achieved an accuracy of {accuracy_score(y_test, y_rf_pred)}.\")\n",
        "print(f\"The support vector machine model achieved an accuracy of {accuracy_score(y_test, y_svm_pred)}.\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The random forest model achieved an accuracy of 0.9736842105263158.\n",
            "The support vector machine model achieved an accuracy of 0.9210526315789473.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNFM7Hzn8woV",
        "outputId": "1cf995b5-76d0-4d3f-a8e2-43e6c45c490e"
      },
      "source": [
        "# Since we used a Linear SVM, we can easily determine the coefficients for the features:\n",
        "if isinstance(svm_clf, LinearSVC):\n",
        "    print(svm_clf.coef_)\n",
        "elif isinstance(svm_clf, GridSearchCV):\n",
        "    print(svm_clf.best_estimator_.coef_)\n",
        "\n",
        "print(\"Each class gets a coefficient for each feature that helps us determine that feature's importance.\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.21778416  0.39842162 -0.83300797 -0.41992672]\n",
            " [ 0.02073497 -0.79388423  0.40040623 -0.92633246]\n",
            " [-1.08571571 -0.78185112  1.61136988  1.50149575]]\n",
            "Each class gets a coefficient for each feature that helps us determine that feature's importance.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fG7Px0zP8woW"
      },
      "source": [
        "Now let's look at how we can use explainers, namely the [AnchorTabular](https://docs.seldon.io/projects/alibi/en/stable/methods/Anchors.html#id3) explainer to understand why the models make the predictions they do."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEvSO5uQ8woX"
      },
      "source": [
        "from alibi.explainers import AnchorTabular"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qxtgg0x38woX"
      },
      "source": [
        "Alibi explainers follow a general structure of:\n",
        "\n",
        "1. Initialize the explainer, providing a prediction function, and explainer specific parameters. `exp = Explainer(predict_func, param_1, param_2, ...)`\n",
        "1. Fit the explainer to the training data (this step is explainer dependent) `exp.fit(train_data)`\n",
        "1. Explain a given sample `exp.explain(sample)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v75ecny8woX"
      },
      "source": [
        "First, we reframe the prediction pipeline into a prediction function that we can use with the explainer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdwfFfUo8woY"
      },
      "source": [
        "rf_clf_func = lambda x: rf_clf.predict(x)\n",
        "svm_clf_func = lambda x: svm_clf.predict(x)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHMDZmZB8woY"
      },
      "source": [
        "Now we can instantiate the explainer using the prediction function and any parameters the explainer requires:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK4sl7y28woZ",
        "outputId": "ee04c0cb-1b97-4264-98c7-6ed3c5181d38"
      },
      "source": [
        "rf_explainer = AnchorTabular(rf_clf_func, data[\"feature_names\"])\n",
        "rf_explainer.fit(X_train)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AnchorTabular(meta={\n",
              "  'name': 'AnchorTabular',\n",
              "  'type': ['blackbox'],\n",
              "  'explanations': ['local'],\n",
              "  'params': {'disc_perc': (25, 50, 75), 'seed': None}}\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvxthLlf8woa",
        "outputId": "1dbb6dc2-42f1-4c78-b6dd-403b84f6c656"
      },
      "source": [
        "svm_explainer = AnchorTabular(svm_clf_func, data[\"feature_names\"])\n",
        "svm_explainer.fit(X_train)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AnchorTabular(meta={\n",
              "  'name': 'AnchorTabular',\n",
              "  'type': ['blackbox'],\n",
              "  'explanations': ['local'],\n",
              "  'params': {'disc_perc': (25, 50, 75), 'seed': None}}\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuHdE3ry8woa"
      },
      "source": [
        "Once the explainer is set up, we can now use it to `.explain` samples! Pick a sample below to explain the two models' predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LB5kBU8H8woa",
        "outputId": "f84da7d1-f8fc-4fb1-9600-be5e4c65428c"
      },
      "source": [
        "# Change this value to choose a test sample\n",
        "index_to_explain = 7\n",
        "\n",
        "\n",
        "rf_explanation = rf_explainer.explain(X_test[index_to_explain])\n",
        "svm_explanation = svm_explainer.explain(X_test[index_to_explain])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Could not find an result satisfying the 0.95 precision constraint. Now returning the best non-eligible result.\n",
            "Could not find an result satisfying the 0.95 precision constraint. Now returning the best non-eligible result.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46ber4Nk8wob",
        "outputId": "aca67469-e24f-45b1-83f3-835ff46b0fa5"
      },
      "source": [
        "rf_explanation.anchor, rf_explanation.precision"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['1.58 < petal length (cm) <= 5.20',\n",
              "  '0.30 < petal width (cm) <= 1.90',\n",
              "  'sepal length (cm) > 6.50',\n",
              "  'sepal width (cm) > 3.00'],\n",
              " 0.7628657921291625)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RyJqF6O8wob",
        "outputId": "21daf457-61f9-4f69-942b-92dcccf3787c"
      },
      "source": [
        "svm_explanation.anchor, svm_explanation.precision"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['petal width (cm) <= 1.90',\n",
              "  '4.25 < petal length (cm) <= 5.20',\n",
              "  'sepal length (cm) > 6.50',\n",
              "  '3.00 < sepal width (cm) <= 3.30'],\n",
              " 0.9412997903563941)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1dQQOgh8woc"
      },
      "source": [
        "Here we can see what the model's explanation for the classification of that sample is. You can see that even with our relatively interpretable model of Linear SVMs, these explainers can provide a more direct and intuitive explanation for why a sample was labeled the way it was.\n",
        "\n",
        "Now that you've seen the general approach for these explainers, let's work on something a bit more complex. Now you'll have to create the models, the prediction function, and the explainers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khDUAqME8woc"
      },
      "source": [
        "## Explaining MNIST predictions\n",
        "\n",
        "Explaining data from measured observations is simple enough. Now let's try explaining how images get labeled."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CF6G46D8woc"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6z0RT4C8wod",
        "outputId": "e2e909f0-b143-40d6-cf3b-a9e82a5e8b05"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndqNGhDQ8wod"
      },
      "source": [
        "sample_index = 12\n",
        "sample = x_train[sample_index]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "xSu8w5-L8wod",
        "outputId": "b3b51880-336b-4583-a8fb-81e821729a70"
      },
      "source": [
        "plt.imshow(sample, cmap=\"gray\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3efced5358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ede0ab7718e54dbd9bd0656b3d195a55",
          "grade": false,
          "grade_id": "cell-0a1be97070f65961",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoRdns_-8wod",
        "outputId": "e83293fe-7c5b-46ce-f1b6-d476c25b60e8"
      },
      "source": [
        "## Create a neural network model that should do well on the MNIST dataset and save it to mnist_nn\n",
        "## Make the neural network sufficiently complex (at least 5 layers) and feel free to use Conv2D layers for example\n",
        "\n",
        "## Save the neural network to mnist_nn\n",
        "## You'll need to make sure you get at least 80% accuracy\n",
        "\n",
        "mnist_nn = Sequential()\n",
        "mnist_nn.add(Conv2D(32,(3,3),activation='relu', input_shape=(28, 28, 1)))\n",
        "mnist_nn.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "mnist_nn.add(MaxPool2D((2, 2)))\n",
        "mnist_nn.add(Dropout(.25))\n",
        "mnist_nn.add(Flatten())\n",
        "mnist_nn.add(Dense(128, activation='relu'))\n",
        "mnist_nn.add(Dropout(.5))\n",
        "mnist_nn.add(Dense(10, activation='softmax'))\n",
        "\n",
        "mnist_nn.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "mnist_nn.fit(x_train.reshape(-1, 28, 28 ,1), y_train, epochs=1)\n",
        "mnist_nn.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 142s 76ms/step - loss: 0.4577 - accuracy: 0.8990\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "01b37abef0ca1da0df8c8f3f2b4025b2",
          "grade": true,
          "grade_id": "cell-e394a89e99cb2485",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7QagKIZ8woe",
        "outputId": "65acea23-c227-4e96-84b8-205f0b248ca6"
      },
      "source": [
        "assert len(mnist_nn.layers) > 5\n",
        "assert mnist_nn.evaluate(x_test.reshape(-1, 28, 28 ,1), y_test)[1] > 0.8"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 5s 17ms/step - loss: 0.0727 - accuracy: 0.9766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_bDUFRp8woe"
      },
      "source": [
        "from alibi.explainers import AnchorImage"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh91LeIz8wof"
      },
      "source": [
        "To work with images, we'll use the [AnchorImage](https://docs.seldon.io/projects/alibi/en/stable/methods/Anchors.html#id5) explainer. This explainer requires that we break up the image into \"superpixels\". We'll use the function in the next cell to do just that. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPIgEOV68wof"
      },
      "source": [
        "def superpixel(image, size=(4, 4)):\n",
        "    segments = np.zeros([image.shape[0], image.shape[1]])\n",
        "    row_idx, col_idx = np.where(segments == 0)\n",
        "    for i, j in zip(row_idx, col_idx):\n",
        "        segments[i, j] = int((image.shape[1]/size[1]) * (i//size[0]) + j//size[1])\n",
        "    return segments"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "wtjwVswv8wof",
        "outputId": "2994f3a5-1864-4005-f510-5e34ee0dc67a"
      },
      "source": [
        "segments = superpixel(x_train[0])\n",
        "plt.imshow(segments)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3ea9f8f2e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awTfNeCE8wof"
      },
      "source": [
        "Each presented square is a superpixel. You can change the code above to test out other ways of determining superpixels. You could even just simply change the size from 4,4 to a different size and see what happens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "cbd424c67b4f3c7e21b06bc6d9b12a5f",
          "grade": false,
          "grade_id": "cell-2b6099964aa0a2be",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "VSV5RzP-8wog"
      },
      "source": [
        "# Create an explainer object using AnchorImage that explains the mnist_nn model you created.\n",
        "# Make sure to use the superpixel function as the segmentation function \n",
        "\n",
        "mnist_explainer = AnchorImage(mnist_nn,(28, 28),superpixel)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "492e1773d0063d2a1a2f8a2ed1f49592",
          "grade": true,
          "grade_id": "cell-f81be29970fdaf29",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "CcSU3Xy08wog"
      },
      "source": [
        "assert isinstance(mnist_explainer, AnchorImage)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUa76nGH8wog"
      },
      "source": [
        "# Change this number and try out different samples\n",
        "image_index_to_explain = 2\n",
        "image_to_explain = x_test.reshape(-1, 28, 28 ,1)[image_index_to_explain]"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "aziB3RMw8wog",
        "outputId": "2982b8d1-0fcc-424a-9bb5-0f5acdc06592"
      },
      "source": [
        "plt.imshow(image_to_explain[:,:,0], cmap=\"gray\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3ead2fc5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNRrptrt8woh"
      },
      "source": [
        "# Change the value of p_sample, and threshold here to see how the explanation changes based on the sample.\n",
        "mnist_image_explanation = mnist_explainer.explain(image_to_explain, threshold=.9, p_sample=.5)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "Mxm2Hn548woh",
        "outputId": "6b194adc-6924-420d-bb77-ac28c2b87200"
      },
      "source": [
        "print(f\"The model predicted the number as a {mnist_nn.predict(image_to_explain.reshape(1, 28, 28, 1)).argmax()} because of:\")\n",
        "plt.imshow(mnist_image_explanation.anchor[:,:,0], cmap=\"gray\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model predicted the number as a 1 because of:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3ea9ee0978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-7aL9Sl8woh"
      },
      "source": [
        "One thing you may have noticed is that the explanations are heavily dependent on the superpixels we identify. Have ideas for a better superpixel definition? Go back and try it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gnEMSTt8woh"
      },
      "source": [
        "## Explaining newsgroup predictions\n",
        "\n",
        "With the newsgroup dataset we'll look at explaining how text gets predicted using [AnchorText](https://docs.seldon.io/projects/alibi/en/v0.2.2/methods/Anchors.html#Initialization)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1tOykoB8woi"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import spacy\n",
        "from alibi.explainers import AnchorText\n",
        "from alibi.utils.download import spacy_model\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wE9DCyqf8woi",
        "outputId": "17e9d4d8-7f7d-4aea-8033-7232d37804a2"
      },
      "source": [
        "newsgroups = fetch_20newsgroups()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWfUyp748woi",
        "outputId": "49fd7a9c-5d24-4d36-bf3d-f026fed03f11"
      },
      "source": [
        "print(newsgroups[\"DESCR\"])\n",
        "text = newsgroups[\"data\"]\n",
        "news_labels = newsgroups[\"target\"]\n",
        "newsgroup_names = newsgroups[\"target_names\"]\n",
        "\n",
        "text_train, text_test, labels_train, labels_test = train_test_split(text, news_labels, random_state=0)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _20newsgroups_dataset:\n",
            "\n",
            "The 20 newsgroups text dataset\n",
            "------------------------------\n",
            "\n",
            "The 20 newsgroups dataset comprises around 18000 newsgroups posts on\n",
            "20 topics split in two subsets: one for training (or development)\n",
            "and the other one for testing (or for performance evaluation). The split\n",
            "between the train and test set is based upon a messages posted before\n",
            "and after a specific date.\n",
            "\n",
            "This module contains two loaders. The first one,\n",
            ":func:`sklearn.datasets.fetch_20newsgroups`,\n",
            "returns a list of the raw texts that can be fed to text feature\n",
            "extractors such as :class:`sklearn.feature_extraction.text.CountVectorizer`\n",
            "with custom parameters so as to extract feature vectors.\n",
            "The second one, :func:`sklearn.datasets.fetch_20newsgroups_vectorized`,\n",
            "returns ready-to-use features, i.e., it is not necessary to use a feature\n",
            "extractor.\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    =================   ==========\n",
            "    Classes                     20\n",
            "    Samples total            18846\n",
            "    Dimensionality               1\n",
            "    Features                  text\n",
            "    =================   ==========\n",
            "\n",
            "Usage\n",
            "~~~~~\n",
            "\n",
            "The :func:`sklearn.datasets.fetch_20newsgroups` function is a data\n",
            "fetching / caching functions that downloads the data archive from\n",
            "the original `20 newsgroups website`_, extracts the archive contents\n",
            "in the ``~/scikit_learn_data/20news_home`` folder and calls the\n",
            ":func:`sklearn.datasets.load_files` on either the training or\n",
            "testing set folder, or both of them::\n",
            "\n",
            "  >>> from sklearn.datasets import fetch_20newsgroups\n",
            "  >>> newsgroups_train = fetch_20newsgroups(subset='train')\n",
            "\n",
            "  >>> from pprint import pprint\n",
            "  >>> pprint(list(newsgroups_train.target_names))\n",
            "  ['alt.atheism',\n",
            "   'comp.graphics',\n",
            "   'comp.os.ms-windows.misc',\n",
            "   'comp.sys.ibm.pc.hardware',\n",
            "   'comp.sys.mac.hardware',\n",
            "   'comp.windows.x',\n",
            "   'misc.forsale',\n",
            "   'rec.autos',\n",
            "   'rec.motorcycles',\n",
            "   'rec.sport.baseball',\n",
            "   'rec.sport.hockey',\n",
            "   'sci.crypt',\n",
            "   'sci.electronics',\n",
            "   'sci.med',\n",
            "   'sci.space',\n",
            "   'soc.religion.christian',\n",
            "   'talk.politics.guns',\n",
            "   'talk.politics.mideast',\n",
            "   'talk.politics.misc',\n",
            "   'talk.religion.misc']\n",
            "\n",
            "The real data lies in the ``filenames`` and ``target`` attributes. The target\n",
            "attribute is the integer index of the category::\n",
            "\n",
            "  >>> newsgroups_train.filenames.shape\n",
            "  (11314,)\n",
            "  >>> newsgroups_train.target.shape\n",
            "  (11314,)\n",
            "  >>> newsgroups_train.target[:10]\n",
            "  array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])\n",
            "\n",
            "It is possible to load only a sub-selection of the categories by passing the\n",
            "list of the categories to load to the\n",
            ":func:`sklearn.datasets.fetch_20newsgroups` function::\n",
            "\n",
            "  >>> cats = ['alt.atheism', 'sci.space']\n",
            "  >>> newsgroups_train = fetch_20newsgroups(subset='train', categories=cats)\n",
            "\n",
            "  >>> list(newsgroups_train.target_names)\n",
            "  ['alt.atheism', 'sci.space']\n",
            "  >>> newsgroups_train.filenames.shape\n",
            "  (1073,)\n",
            "  >>> newsgroups_train.target.shape\n",
            "  (1073,)\n",
            "  >>> newsgroups_train.target[:10]\n",
            "  array([0, 1, 1, 1, 0, 1, 1, 0, 0, 0])\n",
            "\n",
            "Converting text to vectors\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "In order to feed predictive or clustering models with the text data,\n",
            "one first need to turn the text into vectors of numerical values suitable\n",
            "for statistical analysis. This can be achieved with the utilities of the\n",
            "``sklearn.feature_extraction.text`` as demonstrated in the following\n",
            "example that extract `TF-IDF`_ vectors of unigram tokens\n",
            "from a subset of 20news::\n",
            "\n",
            "  >>> from sklearn.feature_extraction.text import TfidfVectorizer\n",
            "  >>> categories = ['alt.atheism', 'talk.religion.misc',\n",
            "  ...               'comp.graphics', 'sci.space']\n",
            "  >>> newsgroups_train = fetch_20newsgroups(subset='train',\n",
            "  ...                                       categories=categories)\n",
            "  >>> vectorizer = TfidfVectorizer()\n",
            "  >>> vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
            "  >>> vectors.shape\n",
            "  (2034, 34118)\n",
            "\n",
            "The extracted TF-IDF vectors are very sparse, with an average of 159 non-zero\n",
            "components by sample in a more than 30000-dimensional space\n",
            "(less than .5% non-zero features)::\n",
            "\n",
            "  >>> vectors.nnz / float(vectors.shape[0])\n",
            "  159.01327...\n",
            "\n",
            ":func:`sklearn.datasets.fetch_20newsgroups_vectorized` is a function which \n",
            "returns ready-to-use token counts features instead of file names.\n",
            "\n",
            ".. _`20 newsgroups website`: http://people.csail.mit.edu/jrennie/20Newsgroups/\n",
            ".. _`TF-IDF`: https://en.wikipedia.org/wiki/Tf-idf\n",
            "\n",
            "\n",
            "Filtering text for more realistic training\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "It is easy for a classifier to overfit on particular things that appear in the\n",
            "20 Newsgroups data, such as newsgroup headers. Many classifiers achieve very\n",
            "high F-scores, but their results would not generalize to other documents that\n",
            "aren't from this window of time.\n",
            "\n",
            "For example, let's look at the results of a multinomial Naive Bayes classifier,\n",
            "which is fast to train and achieves a decent F-score::\n",
            "\n",
            "  >>> from sklearn.naive_bayes import MultinomialNB\n",
            "  >>> from sklearn import metrics\n",
            "  >>> newsgroups_test = fetch_20newsgroups(subset='test',\n",
            "  ...                                      categories=categories)\n",
            "  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\n",
            "  >>> clf = MultinomialNB(alpha=.01)\n",
            "  >>> clf.fit(vectors, newsgroups_train.target)\n",
            "  MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
            "\n",
            "  >>> pred = clf.predict(vectors_test)\n",
            "  >>> metrics.f1_score(newsgroups_test.target, pred, average='macro')\n",
            "  0.88213...\n",
            "\n",
            "(The example :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py` shuffles\n",
            "the training and test data, instead of segmenting by time, and in that case\n",
            "multinomial Naive Bayes gets a much higher F-score of 0.88. Are you suspicious\n",
            "yet of what's going on inside this classifier?)\n",
            "\n",
            "Let's take a look at what the most informative features are:\n",
            "\n",
            "  >>> import numpy as np\n",
            "  >>> def show_top10(classifier, vectorizer, categories):\n",
            "  ...     feature_names = np.asarray(vectorizer.get_feature_names())\n",
            "  ...     for i, category in enumerate(categories):\n",
            "  ...         top10 = np.argsort(classifier.coef_[i])[-10:]\n",
            "  ...         print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n",
            "  ...\n",
            "  >>> show_top10(clf, vectorizer, newsgroups_train.target_names)\n",
            "  alt.atheism: edu it and in you that is of to the\n",
            "  comp.graphics: edu in graphics it is for and of to the\n",
            "  sci.space: edu it that is in and space to of the\n",
            "  talk.religion.misc: not it you in is that and to of the\n",
            "\n",
            "\n",
            "You can now see many things that these features have overfit to:\n",
            "\n",
            "- Almost every group is distinguished by whether headers such as\n",
            "  ``NNTP-Posting-Host:`` and ``Distribution:`` appear more or less often.\n",
            "- Another significant feature involves whether the sender is affiliated with\n",
            "  a university, as indicated either by their headers or their signature.\n",
            "- The word \"article\" is a significant feature, based on how often people quote\n",
            "  previous posts like this: \"In article [article ID], [name] <[e-mail address]>\n",
            "  wrote:\"\n",
            "- Other features match the names and e-mail addresses of particular people who\n",
            "  were posting at the time.\n",
            "\n",
            "With such an abundance of clues that distinguish newsgroups, the classifiers\n",
            "barely have to identify topics from text at all, and they all perform at the\n",
            "same high level.\n",
            "\n",
            "For this reason, the functions that load 20 Newsgroups data provide a\n",
            "parameter called **remove**, telling it what kinds of information to strip out\n",
            "of each file. **remove** should be a tuple containing any subset of\n",
            "``('headers', 'footers', 'quotes')``, telling it to remove headers, signature\n",
            "blocks, and quotation blocks respectively.\n",
            "\n",
            "  >>> newsgroups_test = fetch_20newsgroups(subset='test',\n",
            "  ...                                      remove=('headers', 'footers', 'quotes'),\n",
            "  ...                                      categories=categories)\n",
            "  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\n",
            "  >>> pred = clf.predict(vectors_test)\n",
            "  >>> metrics.f1_score(pred, newsgroups_test.target, average='macro')\n",
            "  0.77310...\n",
            "\n",
            "This classifier lost over a lot of its F-score, just because we removed\n",
            "metadata that has little to do with topic classification.\n",
            "It loses even more if we also strip this metadata from the training data:\n",
            "\n",
            "  >>> newsgroups_train = fetch_20newsgroups(subset='train',\n",
            "  ...                                       remove=('headers', 'footers', 'quotes'),\n",
            "  ...                                       categories=categories)\n",
            "  >>> vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
            "  >>> clf = MultinomialNB(alpha=.01)\n",
            "  >>> clf.fit(vectors, newsgroups_train.target)\n",
            "  MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
            "\n",
            "  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\n",
            "  >>> pred = clf.predict(vectors_test)\n",
            "  >>> metrics.f1_score(newsgroups_test.target, pred, average='macro')\n",
            "  0.76995...\n",
            "\n",
            "Some other classifiers cope better with this harder version of the task. Try\n",
            "running :ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py` with and without\n",
            "the ``--filter`` option to compare the results.\n",
            "\n",
            ".. topic:: Recommendation\n",
            "\n",
            "  When evaluating text classifiers on the 20 Newsgroups data, you\n",
            "  should strip newsgroup-related metadata. In scikit-learn, you can do this by\n",
            "  setting ``remove=('headers', 'footers', 'quotes')``. The F-score will be\n",
            "  lower because it is more realistic.\n",
            "\n",
            ".. topic:: Examples\n",
            "\n",
            "   * :ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py`\n",
            "\n",
            "   * :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py`\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AeEojic8woj",
        "outputId": "d2863acd-cc2d-4da8-c8ba-5ad26c78ea18"
      },
      "source": [
        "# Creating a TFIDF vectorizer and Linear SVM classifier to make predictions about the newsgroup dataset\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf.fit(text_train)\n",
        "\n",
        "clf = LinearSVC()\n",
        "clf.fit(tfidf.transform(text_train), labels_train)\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "          verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c38e085a0f04503420ab1c4d3e804f3d",
          "grade": false,
          "grade_id": "cell-9328ed37549d0d6c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "wCDo1njL8wok"
      },
      "source": [
        "# Create newsgroup_predictor which is a predictor function to use with an AnchorText predictor using\n",
        "# the vectorizer and classifier defined in the cell above\n",
        "# Note that you have to transform the data with the vectorizer and then predict it.\n",
        "newsgroup_predictor = lambda x: clf.predict(tfidf.transform(x))"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "67f9943d90704e2342af4565b08ca501",
          "grade": true,
          "grade_id": "cell-f5ed32ccd8efa182",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "o4e4IGmD8wok"
      },
      "source": [
        "assert len(newsgroup_predictor(text_test[:2])) == 2"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4iZAOWX8wok"
      },
      "source": [
        "model = 'en_core_web_md'\n",
        "spacy_model(model=model)\n",
        "nlp = spacy.load(model)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v0SIAB38wol"
      },
      "source": [
        "# Create the explainer to use\n",
        "newsgroup_explainer = AnchorText(nlp, newsgroup_predictor)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a974c89bfd3e84c2ecdccc4fa0fd6cc4",
          "grade": false,
          "grade_id": "cell-57dc731897b7b73a",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "Igika4ok8wol"
      },
      "source": [
        "# Copy the text of an article you find on the internet and save it as article\n",
        "\n",
        "article = \"There’s more to enzyme action than correct folding. Many proteins are chemically modified after being translated on the ribosome: parts of the peptide chain may be crosslinked, and non-amino-acid groups such as porphyrins or metal ions are incorporated. Besides, knowing the structure doesn’t by itself tell you the function. Sometimes this can be deduced by analogy, or rather, homology: proteins with similar folds may have similar functions. But that’s not invariably true: proteins with very similar structures can behave in chemically very different ways, while very different folds can achieve similar transformations. There is no unique structure-function relationship. What’s more, designing a ligand for a protein can be challenging even if you know its structure very accurately, partly because we don’t know all the rules of recognition – some depend, for example, on fine details of solvation at the active site. And for drug discovery the biggest hurdles are typically upstream from the identification of a potential molecular target – not least because it often proves to be the wrong target. In any case, the picture in which protein function is determined by a unique and static crystal structure is known now to be far too simplistic. The dynamics might be crucial. Ligand binding typically involves some flexibility and adaptation at the active site – but more generally, the emerging view of protein function invokes the ensemble of conformations accessible to it: the statistical populations and occupancy times of the different dynamic states it can reach. What’s more, many proteins don’t have well-defined folded conformations at all, but contain ‘intrinsically disordered’, floppy parts of the peptide chain. That’s not nature being sloppy: the disorder and resulting flexibility seems to be functional. AI approaches may well identify which sequences are likely to be disordered, but that alone won’t help to understand their behaviour. Finally, any deep-learning system is only competent within the bounds of its training set. We don’t know the size of the human proteome, but some estimates say that only around 5% of all human proteins have been crystallised and their structure determined. So the training data are likely to be biased towards the structures that are relatively easy to solve. Some researchers think there could be a systematic repertoire of protein structures that we just don’t know about. But such assertions have been contested. Some biochemists pointed out that the accuracy of prediction was not always so impressive and is in general unlikely to be accepted without experimental corroboration from, say, crystallography, NMR studies or cryo-electron microscopy. While the majority of predicted structures were within experimental resolution, one can’t tell a priori which are and which aren’t – so you need experiments to check. Also, it’s still not yet clear that the accuracy meets what’s needed for, say, finding drug candidates that might bind to the protein’s active site to block its function. Others take issue with the notion that the method ‘solves the protein folding problem’ at all. Since the pioneering work of Christian Anfinsen in the 1950s, it has been known that unravelled (denatured) protein molecules may regain their ‘native’ conformation spontaneously, implying that the peptide sequence alone encodes the rules for correct folding. The challenge was to find those rules and predict the folding path. AlphaFold has not done this. It says nothing about the mechanism of folding, but just predicts the structure using standard machine learning. It finds correlations between sequence and structure by being trained on the 170,000 or so known structures in the Protein Data Base: the algorithm doesn’t so much solve the protein-folding problem as evade it. How it ‘reasons’ from sequence to structure remains a black box.If some see this as cheating, that doesn’t much matter for practical purposes. It will surely be valuable to deduce even a good guess at the structure from just the sequence. From that we can often make inferences about the protein’s function and the chemical mechanism of its mode of action. And ‘good enough’ predictions can be a useful starting point for refinement with crystallographic data. \""
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "df107c35762a3a1b35781cf14f5e45b6",
          "grade": true,
          "grade_id": "cell-501e6db67729a04d",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "DpQbtv8W8wol"
      },
      "source": [
        "assert len(article) > 500"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2524df710c7c0101f986a026d004aadc",
          "grade": false,
          "grade_id": "cell-24c6bbba046e8fd4",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "PAVfO7Lp8wol",
        "outputId": "3459da84-a1bd-4e99-d5f0-a14ece2c5c6c"
      },
      "source": [
        "# Define article_explanation as the explainer's explanation for the article you provided.\n",
        "\n",
        "article_explanation = newsgroup_explainer.explain(article)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4ee3ef5dbc61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define article_explanation as the explainer's explanation for the article you provided.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0marticle_explanation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewsgroup_explainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'newsgroup_explainer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJd2w8QJ8wom"
      },
      "source": [
        "print(f\"The model predicted the article as {newsgroup_names[newsgroup_predictor([article])[0]]} because of the word: {article_explanation.anchor}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uY3WIeFx8wom"
      },
      "source": [
        "# Change this number and try out different samples\n",
        "test_sample_index = 28\n",
        "test_sample = text_test[test_sample_index]\n",
        "print(test_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwL_xyI78wom"
      },
      "source": [
        "test_sample_explanation = newsgroup_explainer.explain(test_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIRFLwJD8won"
      },
      "source": [
        "print(f\"The model predicted the test sample as {newsgroup_names[newsgroup_predictor([test_sample])[0]]} because of the word {test_sample_explanation.anchor}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GGDsL2L8won"
      },
      "source": [
        "## Feedback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6ff0d8bed14ed80b45c8ae821e8967e6",
          "grade": false,
          "grade_id": "cell-523ebab8f9ab57b8",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "fmYFJ76J8won"
      },
      "source": [
        "def feedback():\n",
        "    \"\"\"Provide feedback on the contents of this exercise\n",
        "    \n",
        "    Returns:\n",
        "        string\n",
        "    \"\"\"\n",
        "    return \"I liked this assignment\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH2leopE8woo"
      },
      "source": [
        "feedback()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}